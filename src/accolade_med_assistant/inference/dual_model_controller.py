from dataclasses import asdict
import json
import re
from typing import Any

from accolade_med_assistant.inference.local_llm import LocalLLMClient
from accolade_med_assistant.models.types import Intake


class MedgemmaTriageSchema:
    """Strict schema validator/coercer for MedGemma triage output."""

    allowed_urgencies = {"emergency", "urgent", "routine"}

    @classmethod
    def parse(cls, payload: dict[str, Any] | None) -> dict[str, Any] | None:
        if not isinstance(payload, dict):
            return None

        urgency = str(payload.get("urgency", "")).strip().lower()
        if urgency not in cls.allowed_urgencies:
            return None

        next_step = str(payload.get("recommended_next_step", "")).strip()
        if not next_step:
            return None

        raw_actions = payload.get("immediate_actions", [])
        if not isinstance(raw_actions, list):
            return None
        actions = [str(a).strip() for a in raw_actions if str(a).strip()]
        if not actions:
            return None

        rationale = str(payload.get("rationale", "")).strip()
        if not rationale:
            rationale = "Recommendation generated by MedGemma."

        return {
            "urgency": urgency,
            "recommended_next_step": next_step,
            "immediate_actions": actions,
            "rationale": rationale,
        }


class DualModelController:
    """Orchestrates DeepSeek (decider) + MedGemma (medical reasoning)."""

    def __init__(self, decider_llm: LocalLLMClient | None = None, medgemma_llm: LocalLLMClient | None = None) -> None:
        self.decider_llm = decider_llm or LocalLLMClient(
            model_name="mistralai/Mistral-7B-Instruct-v0.3", backend="deepseek"
        )
        self.medgemma_llm = medgemma_llm or LocalLLMClient(
            model_name="google/medgemma-1.5-4b-it", backend="medgemma"
        )

    def should_call_medgemma(self, intake: Intake) -> tuple[bool, str]:
        prompt = (
            "You are a triage model router. Decide whether MedGemma (medical multimodal model) "
            "should be called for this case.\n"
            "Return STRICT JSON only: {\"call_medgemma\": true/false, \"reason\": \"...\"}.\n"
            "Call MedGemma when case seems medically complex, urgent, image-dependent, or uncertain.\n"
            f"Case: {asdict(intake)}"
        )

        text = self.decider_llm.generate_text(prompt)
        parsed = self._extract_json(text)
        if parsed is not None and isinstance(parsed.get("call_medgemma"), bool):
            return parsed["call_medgemma"], str(parsed.get("reason", "Decision from DeepSeek router."))

        return self._heuristic_medgemma_decision(intake)

    def medgemma_recommendations(self, intake: Intake) -> tuple[dict[str, Any] | None, str | None]:
        prompt = (
            "You are a medical triage assistant. Provide practical next-step recommendations.\n"
            "Output MUST be STRICT JSON only. No markdown, no bullets, no analysis, no chain-of-thought.\n"
            "Do not include keys other than these:\n"
            "{\"urgency\": \"emergency|urgent|routine\", \"recommended_next_step\": \"...\", "
            "\"immediate_actions\": [\"...\", \"...\"], \"rationale\": \"...\"}.\n"
            "Keep recommended_next_step under 18 words and immediate_actions as 2-4 concise commands.\n"
            f"Case: {asdict(intake)}"
        )

        raw = self.medgemma_llm.generate_text(prompt, scan_image_path=intake.scan_image_path)
        raw = self._sanitize_medgemma_text(raw)
        parsed = self._extract_json(raw)
        structured = MedgemmaTriageSchema.parse(parsed)
        if structured is None:
            return None, raw
        return structured, raw

    def _heuristic_medgemma_decision(self, intake: Intake) -> tuple[bool, str]:
        text = f"{' '.join(intake.symptoms)} {intake.notes} {intake.scan_findings or ''}".lower()
        triggers = (
            "shortness of breath",
            "chest pain",
            "stroke",
            "seizure",
            "bleeding",
            "coughing blood",
            "unconscious",
            "pregnant",
        )
        if intake.scan_image_path:
            return True, "Image provided; call MedGemma for medical multimodal interpretation."
        if any(t in text for t in triggers):
            return True, "High-risk or complex symptoms detected; call MedGemma."
        return False, "Case appears straightforward; MedGemma not required."

    def _extract_json(self, text: str | None) -> dict[str, Any] | None:
        if not text:
            return None

        text = text.strip()
        try:
            payload = json.loads(text)
            if isinstance(payload, dict):
                return payload
        except json.JSONDecodeError:
            pass

        match = re.search(r"\{.*\}", text, re.DOTALL)
        if not match:
            return None
        try:
            payload = json.loads(match.group(0))
            if isinstance(payload, dict):
                return payload
        except json.JSONDecodeError:
            return None
        return None

    def _sanitize_medgemma_text(self, text: str | None) -> str | None:
        if not text:
            return text
        cleaned = text.strip()
        cleaned = re.sub(r"<unused\d+>\s*thought\b", "", cleaned, flags=re.IGNORECASE).strip()
        cleaned = re.sub(r"^\s*thought\b", "", cleaned, flags=re.IGNORECASE).strip()
        # Drop known prompt-echo/instruction leakage patterns.
        if self._looks_like_prompt_echo(cleaned):
            return None
        return cleaned

    def _looks_like_prompt_echo(self, text: str) -> bool:
        lowered = text.lower().strip()
        markers = (
            "the user wants me to act as",
            "output must be strict json",
            "do not include keys other than",
            "no markdown, no bullets, no analysis",
            "provide a json output",
            "keys should only be",
        )
        return any(marker in lowered for marker in markers)
